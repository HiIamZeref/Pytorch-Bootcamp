{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n",
      "0.18.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Setting device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (FashionMNIST)\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of our datasets\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
      "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
      "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
      "          0.0157, 0.0000, 0.0000, 0.0118],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
      "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0471, 0.0392, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
      "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
      "          0.3020, 0.5098, 0.2824, 0.0588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
      "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
      "          0.5529, 0.3451, 0.6745, 0.2588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
      "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
      "          0.4824, 0.7686, 0.8980, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
      "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
      "          0.8745, 0.9608, 0.6784, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
      "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
      "          0.8627, 0.9529, 0.7922, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
      "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
      "          0.8863, 0.7725, 0.8196, 0.2039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
      "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
      "          0.9608, 0.4667, 0.6549, 0.2196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
      "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
      "          0.8510, 0.8196, 0.3608, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
      "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
      "          0.8549, 1.0000, 0.3020, 0.0000],\n",
      "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
      "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
      "          0.8784, 0.9569, 0.6235, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
      "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
      "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
      "          0.9137, 0.9333, 0.8431, 0.0000],\n",
      "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
      "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
      "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
      "          0.8627, 0.9098, 0.9647, 0.0000],\n",
      "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
      "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
      "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
      "          0.8706, 0.8941, 0.8824, 0.0000],\n",
      "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
      "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
      "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
      "          0.8745, 0.8784, 0.8980, 0.1137],\n",
      "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
      "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
      "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
      "          0.8627, 0.8667, 0.9020, 0.2627],\n",
      "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
      "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
      "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
      "          0.7098, 0.8039, 0.8078, 0.4510],\n",
      "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
      "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
      "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
      "          0.6549, 0.6941, 0.8235, 0.3608],\n",
      "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
      "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
      "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
      "          0.7529, 0.8471, 0.6667, 0.0000],\n",
      "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
      "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
      "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
      "          0.3882, 0.2275, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
      "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]) 9\n"
     ]
    }
   ],
   "source": [
    "# Image and label sample\n",
    "image, label = train_data[0]\n",
    "print(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All dataset labels \n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each value corresponds to a class label\n",
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of class labels\n",
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the image and label shape (image: color channel, height, width)\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the image\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting multiple images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=[1]).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataloader\n",
    "Breaking data into batches.\n",
    "\n",
    "\n",
    "The computer cannot \"look\" to, for example, 6000 thousands images at a time. So we split the data into smaller groups called batches.\n",
    "\n",
    "\n",
    "Normally we use 32 batch size, or, 32 images at a time.\n",
    "\n",
    "Also, it gives our neural network more chances to improve itself by epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f552a5193a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f552a54d2b0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup batch size hyperparameter\n",
    "BATCH_SIZE = 32 # 64, 128, 256, 512, 1024\n",
    "\n",
    "# Creating dataloaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 1875 of size 32\n",
      "Number of testing batches: 313 of size 32\n"
     ]
    }
   ],
   "source": [
    "# Checking how many batches we have\n",
    "print(f\"Number of training batches: {len(train_dataloader)} of size {train_dataloader.batch_size}\")\n",
    "print(f\"Number of testing batches: {len(test_dataloader)} of size {test_dataloader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a batch sample from the dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting image and label from the batch sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(BATCH_SIZE, size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(img.shape)\n",
    "print(class_names[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 0 : Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening: torch.Size([1, 28, 28])\n",
      "After flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the image\n",
    "output = flatten_model(x)\n",
    "print(f\"Before flattening: {x.shape}\")\n",
    "print(f\"After flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layer_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate the model\n",
    "model_0 = FashionMNISTModelV0(input_shape=28*28, \n",
    "                              hidden_units=128,\n",
    "                                output_shape=len(class_names))\n",
    "model_0.to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2292, -0.3081, -0.4636,  0.0714, -0.2627, -0.0312,  0.0321, -0.1599,\n",
       "          0.1276,  0.1425]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand(1, 28, 28).to(device)\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setup loss function, optimizer and evaluation metrics\n",
    "\n",
    "* Loss function - `nn.CrossEntropyLoss()`\n",
    "* Optimizer - `torch.optim.SGD() `(stochastic gradient descent)\n",
    "* Evaluation metric - accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions already exist! Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Importing helper functions\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "if Path(\"helper_functions.py\").exists():\n",
    "    print(\"Helper functions already exist! Skipping download.\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    # Note: you need the \"raw\" GitHub URL for this to work\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr= 0.1) # Tutorial selected optimizer as SGD\n",
    "\n",
    "# optimizer = torch.optim.Adam(model_0.parameters(), lr=1e-3) # Adam: Copilot suggestion\n",
    "# What is Adam?\n",
    "# Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time the experiment\n",
    "\n",
    "Often you want to track to things:\n",
    "1. Model's performance (accuracy, loss)\n",
    "2. How fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time (start: float, end:float, device: torch.device = None):\n",
    "    print(f\"Training time: {end - start:.2f} seconds on device:{device}\")\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Creating a training loop to train the model using batches of data\n",
    "\n",
    "1. Loop through the data\n",
    "2. Loop through the batches, perform training steps, calculate loss *per batch*.\n",
    "3. Loop through testing batches, perform testing steps, calculate loss *per batch*.\n",
    "4. Print it out.\n",
    "5. Time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293846740e0444f8a9caf18f5abdcdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch 0 loss: 2.3405284881591797\n",
      "Batch 400 loss: 0.6049758791923523\n",
      "Batch 800 loss: 0.6499577760696411\n",
      "Batch 1200 loss: 0.3559314012527466\n",
      "Batch 1600 loss: 0.35203197598457336\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch 0 loss: 0.25963032245635986\n",
      "Batch 400 loss: 0.5991396903991699\n",
      "Batch 800 loss: 0.399014949798584\n",
      "Batch 1200 loss: 0.3362348675727844\n",
      "Batch 1600 loss: 0.5327666401863098\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Batch 0 loss: 0.5037592649459839\n",
      "Batch 400 loss: 0.5679938197135925\n",
      "Batch 800 loss: 0.3702755272388458\n",
      "Batch 1200 loss: 0.2893134355545044\n",
      "Batch 1600 loss: 0.422565758228302\n",
      "Train loss: 0.4523, Test loss: 0.5095, Test accuracy: 82.2384\n",
      "Training time: 19.85 seconds on device:cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.849488226001995"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm# tqdm is a library that allows you to display progress bars in Python\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "# Number of epochs\n",
    "EPOCHS = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = 0\n",
    "    for idx, (features, labels) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        # Getting the data to the device\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_0(features)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        train_loss += loss # accumulate loss for each batch\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 400 == 0:\n",
    "            print(f\"Batch {idx} loss: {loss.item()}\")\n",
    "train_loss /= len(train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "test_loss, test_accuracy = 0, 0\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    for features, labels in test_dataloader:\n",
    "        # Getting the data to the device\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_0(features)\n",
    "\n",
    "        # Loss calculation\n",
    "        test_loss += loss_fn(outputs, labels)\n",
    "\n",
    "        # Accuracy calculation\n",
    "        test_accuracy += accuracy_fn(y_true=labels, y_pred=outputs.argmax(dim=1))\n",
    "\n",
    "    # Averaging the loss and accuracy\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy /= len(test_dataloader)  \n",
    "\n",
    "    print(f\"Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "print_train_time(train_time_start, train_time_end, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18167c9d481a4d759e39c8e493914909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'loss': 0.46243253350257874,\n",
       " 'accuracy': 83.94333333333333}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containign the results of the model prediction.\n",
    "    \"\"\"\n",
    "    loss, accuracy = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for features, labels in tqdm(data_loader):\n",
    "            # Getting the data to the device\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "\n",
    "            # Accumulate loss and accuracy for each batch\n",
    "            loss += loss_fn(outputs, labels)\n",
    "            accuracy += accuracy_fn(y_true=labels, y_pred=outputs.argmax(dim=1))\n",
    "\n",
    "        # Averaging the loss and accuracy\n",
    "        loss /= len(data_loader)\n",
    "        accuracy /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, \"loss\": loss.item(), \"accuracy\": accuracy}\n",
    "\n",
    "# Evaluating the model\n",
    "model_0_results = eval_model(model_0, train_dataloader, loss_fn, accuracy_fn)\n",
    "model_0_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 1: Creating a better model with non-linear activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        logits = self.layer_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instacing the model\n",
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=28*28, hidden_units=128, output_shape=len(class_names))\n",
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setting up the loss function and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)\n",
    "accuracy_fn = accuracy_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Functionizing training and testing loops\n",
    "\n",
    "* Training loop - `train_step()`\n",
    "* Testing loop - `test_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device):\n",
    "    \"\"\"\n",
    "    Performs a single training step.\n",
    "    \"\"\"\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for batch, (features, labels) in enumerate(dataloader):\n",
    "        # Getting the data to the device\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass (raw predictions)\n",
    "        outputs = model(features)\n",
    "\n",
    "        # Loss and accuracy calculation \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        train_loss += loss # accumulate loss for each batch\n",
    "\n",
    "        train_accuracy += accuracy_fn(y_true=labels, y_pred=outputs.argmax(dim=1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Averaging the loss and accuracy\n",
    "    train_loss /= len(dataloader)\n",
    "    train_accuracy /= len(dataloader)\n",
    "    print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device):\n",
    "    \"\"\"\n",
    "    Perfoms a test loop for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    test_loss, test_accuracy = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for features, labels in dataloader:\n",
    "            # Getting the data to the device\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "\n",
    "            # Loss calculation\n",
    "            test_loss += loss_fn(outputs, labels)\n",
    "\n",
    "            # Accuracy calculation\n",
    "            test_accuracy += accuracy_fn(y_true=labels, y_pred=outputs.argmax(dim=1))\n",
    "\n",
    "        # Averaging the loss and accuracy\n",
    "        test_loss /= len(dataloader)\n",
    "        test_accuracy /= len(dataloader)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958ddcb57cef4e97bd1a691de59a7c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.3448, Train accuracy: 87.4650\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.3253, Train accuracy: 88.1567\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.3094, Train accuracy: 88.5950\n",
      "Test loss: 0.3649, Test accuracy: 86.9609\n",
      "Training time: 20.13 seconds on device:cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e378c4915f84772add3621247553a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'loss': 0.2974622845649719,\n",
       " 'accuracy': 89.185}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Start timer\n",
    "model_1_train_time_start = timer()\n",
    "\n",
    "# Number of epochs\n",
    "EPOCHS = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_step(model_1, train_dataloader, loss_fn, optimizer, accuracy_fn, device)\n",
    "\n",
    "# Testing the model\n",
    "test_step(model_1, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "\n",
    "# End timer\n",
    "model_1_train_time_end = timer()\n",
    "# Print training time\n",
    "print_train_time(model_1_train_time_start, model_1_train_time_end, device)\n",
    "\n",
    "model_1_results = eval_model(model_1, train_dataloader, loss_fn, accuracy_fn)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'loss': 0.46243253350257874,\n",
       " 'accuracy': 83.94333333333333}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Building a Convolutional Neural Network (CNN)\n",
    "\n",
    "CNNs are the most popular neural network architecture for image classification tasks.\n",
    "\n",
    "CNN's are also know as ConvNets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network model\n",
    "#Copilot sugestion\n",
    "# class FashionMNISTModelV2(nn.Module):\n",
    "#     def __init__(self, in_channels: int, num_classes: int):\n",
    "#         super().__init__()\n",
    "#         self.layer_stack = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(in_features=32*7*7, out_features=128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=128, out_features=num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x: torch.Tensor):\n",
    "#         logits = self.layer_stack(x)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "#Tutorial model\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture that replicates the TinyVGG architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units*2, # copilot is suggesting \"hidden_units*2\", instead of \"hidden_units\"\n",
    "                      kernel_size=3, \n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units*2,\n",
    "                      out_channels=hidden_units*2,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 7*7*hidden_units*2, # Copilot is suggesting 7*7*hidden_units*2 instead of 7*7*hidden_units (7*7 is the output shape of the last MaxPool2d layer)\n",
    "                      out_features= hidden_units*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features= hidden_units*4,\n",
    "                      out_features= output_shape)\n",
    "        )\n",
    "        \n",
    "        # Copilot is suggesting two Linear layers instead of one and hidden_units*4 instead of hidden_units*2\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Stepping through the CNN `nn.Conv2d()`\n",
    "\n",
    "Convolutional layers are the building blocks of CNNs. \n",
    "\n",
    "A convolution is a linear operation that involves the multiplication of a set of weights with the input, much like a fully connected layer. The difference is that the input is usually a 3D volume (width, height, depth) instead of a 1D vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64])\n",
      "Single image shape: torch.Size([3, 64, 64])\n",
      "Test image: tensor([[[0.8823, 0.9150, 0.3829,  ..., 0.1587, 0.6542, 0.3278],\n",
      "         [0.6532, 0.3958, 0.9147,  ..., 0.2083, 0.3289, 0.1054],\n",
      "         [0.9192, 0.4008, 0.9302,  ..., 0.5535, 0.4117, 0.3510],\n",
      "         ...,\n",
      "         [0.1457, 0.1499, 0.3298,  ..., 0.9624, 0.6400, 0.7409],\n",
      "         [0.1709, 0.5797, 0.6340,  ..., 0.6885, 0.2405, 0.5956],\n",
      "         [0.9199, 0.1247, 0.3573,  ..., 0.6752, 0.2058, 0.5027]],\n",
      "\n",
      "        [[0.1458, 0.9024, 0.9217,  ..., 0.1868, 0.6352, 0.8431],\n",
      "         [0.9549, 0.4435, 0.6924,  ..., 0.1168, 0.7160, 0.5462],\n",
      "         [0.1616, 0.1054, 0.8614,  ..., 0.4531, 0.4736, 0.9448],\n",
      "         ...,\n",
      "         [0.4309, 0.3986, 0.1907,  ..., 0.9444, 0.2848, 0.3776],\n",
      "         [0.7948, 0.6855, 0.1009,  ..., 0.6147, 0.7747, 0.2323],\n",
      "         [0.5840, 0.9795, 0.3277,  ..., 0.3549, 0.1263, 0.1280]],\n",
      "\n",
      "        [[0.5027, 0.4195, 0.8893,  ..., 0.3084, 0.1567, 0.7860],\n",
      "         [0.7310, 0.9307, 0.2847,  ..., 0.8432, 0.8307, 0.0897],\n",
      "         [0.7021, 0.5967, 0.7744,  ..., 0.8485, 0.4520, 0.0401],\n",
      "         ...,\n",
      "         [0.5440, 0.0679, 0.6577,  ..., 0.9948, 0.2791, 0.4142],\n",
      "         [0.5095, 0.1246, 0.1726,  ..., 0.0984, 0.3224, 0.3125],\n",
      "         [0.3612, 0.8706, 0.4751,  ..., 0.5368, 0.2389, 0.2095]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Creating batches of images\n",
    "images = torch.rand(size=(32, 3, 64, 64)).to(device)\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single image shape: {test_image.shape}\")\n",
    "print(f\"Test image: {test_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.1770e-02,  3.4358e-02,  3.9181e-02,  ...,  3.4836e-02,\n",
       "            2.1641e-02, -1.8443e-01],\n",
       "          [ 3.6821e-01,  3.7800e-03, -2.4591e-02,  ..., -2.9521e-01,\n",
       "            1.9551e-01, -2.4507e-02],\n",
       "          [-1.4634e-02,  3.5654e-01, -3.5480e-02,  ...,  1.7425e-01,\n",
       "           -1.1074e-01, -1.1926e-02],\n",
       "          ...,\n",
       "          [ 2.4584e-01,  9.2390e-03,  5.6806e-02,  ..., -2.7741e-02,\n",
       "            9.1408e-02,  1.3243e-01],\n",
       "          [-7.6284e-03, -5.1802e-05, -4.4649e-02,  ..., -4.7360e-02,\n",
       "            1.7470e-01,  6.9550e-02],\n",
       "          [-1.4714e-01,  3.5891e-01,  2.8925e-01,  ..., -1.1052e-01,\n",
       "            2.2524e-01, -4.0892e-02]],\n",
       "\n",
       "         [[ 5.8302e-01,  8.6530e-02,  1.5701e-01,  ..., -5.6680e-02,\n",
       "           -5.8010e-02,  3.6485e-01],\n",
       "          [ 9.0060e-02,  4.3645e-01,  4.1854e-01,  ...,  1.3856e-01,\n",
       "            2.5413e-01,  8.3760e-02],\n",
       "          [ 2.8345e-01,  1.8342e-02,  4.5482e-01,  ...,  1.4066e-01,\n",
       "            9.6064e-02,  2.7286e-01],\n",
       "          ...,\n",
       "          [ 4.1874e-01,  2.6714e-01,  1.7156e-01,  ...,  1.3758e-01,\n",
       "           -4.9965e-02,  5.0752e-01],\n",
       "          [-2.1218e-02,  3.0198e-01,  3.2048e-01,  ...,  2.4876e-01,\n",
       "            5.4111e-01,  2.7302e-01],\n",
       "          [ 3.3239e-01,  2.6946e-01,  2.2689e-03,  ...,  3.8455e-01,\n",
       "            2.5257e-01,  5.0546e-01]],\n",
       "\n",
       "         [[ 1.1333e-01, -5.1295e-02,  2.2323e-01,  ...,  2.5013e-01,\n",
       "            6.4086e-02, -3.9931e-02],\n",
       "          [ 1.8702e-01, -2.0802e-01, -8.7472e-02,  ..., -2.9302e-01,\n",
       "            8.4996e-02,  3.2890e-02],\n",
       "          [-5.3973e-02,  5.9074e-02, -4.7262e-03,  ...,  6.1859e-02,\n",
       "            1.3248e-01,  2.6698e-01],\n",
       "          ...,\n",
       "          [-4.3976e-02, -1.9679e-01,  2.1766e-01,  ...,  2.1393e-01,\n",
       "            1.6696e-01,  2.7752e-01],\n",
       "          [ 4.3942e-01,  2.3522e-01, -1.7019e-01,  ...,  1.2737e-01,\n",
       "            1.5028e-01,  2.1903e-01],\n",
       "          [-5.4202e-03,  3.9533e-01, -7.4720e-02,  ..., -8.1187e-02,\n",
       "            2.6160e-01,  1.1321e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.7859e-02, -1.4203e-01, -3.5897e-02,  ...,  9.7424e-02,\n",
       "            1.3232e-01,  1.7681e-01],\n",
       "          [-7.1899e-02,  6.7181e-03,  7.5432e-02,  ...,  2.2658e-01,\n",
       "            2.1773e-01,  1.9494e-02],\n",
       "          [-2.0423e-01,  1.0240e-01,  9.5835e-02,  ...,  1.0116e-01,\n",
       "            4.0845e-02, -1.4610e-01],\n",
       "          ...,\n",
       "          [-1.2580e-02,  5.8162e-02,  1.5175e-01,  ..., -2.0076e-01,\n",
       "            1.5763e-01, -7.8877e-02],\n",
       "          [-2.9473e-02, -2.7259e-01, -1.3678e-01,  ...,  1.4464e-01,\n",
       "            9.8070e-02,  5.2490e-04],\n",
       "          [ 1.5221e-01,  1.3832e-01,  1.7763e-01,  ...,  1.6184e-02,\n",
       "           -1.3620e-01,  7.4652e-03]],\n",
       "\n",
       "         [[-2.6225e-01,  1.6548e-01, -2.9057e-01,  ...,  2.4001e-01,\n",
       "           -2.6472e-01, -1.5793e-01],\n",
       "          [-3.5326e-01, -9.1243e-02,  2.3127e-02,  ...,  1.0210e-01,\n",
       "           -2.7089e-02, -1.6808e-01],\n",
       "          [ 2.4530e-01,  3.0103e-03, -3.5308e-02,  ..., -9.0338e-02,\n",
       "           -1.4759e-02, -2.1336e-01],\n",
       "          ...,\n",
       "          [ 7.4281e-02,  8.3930e-02, -9.4953e-02,  ...,  1.7393e-01,\n",
       "            3.5335e-02,  4.4406e-02],\n",
       "          [ 4.3405e-02, -1.8986e-01, -3.4381e-02,  ...,  1.2752e-01,\n",
       "           -1.9852e-01,  9.1300e-02],\n",
       "          [ 7.8641e-02, -1.8751e-01, -3.6071e-02,  ..., -1.0205e-01,\n",
       "            8.3045e-02, -7.2348e-02]],\n",
       "\n",
       "         [[ 4.3801e-01,  1.5582e-01,  3.3787e-01,  ...,  8.4068e-02,\n",
       "            4.3143e-02,  3.0783e-01],\n",
       "          [ 2.6322e-01,  2.1796e-01,  1.5010e-01,  ..., -7.3062e-02,\n",
       "            2.9283e-01,  2.9020e-01],\n",
       "          [ 2.7090e-01,  2.6103e-01,  6.3895e-02,  ...,  5.7166e-02,\n",
       "           -4.4902e-02,  1.6709e-01],\n",
       "          ...,\n",
       "          [ 1.9146e-01,  2.4683e-02, -4.0129e-02,  ..., -6.8927e-02,\n",
       "           -7.1571e-02,  2.3505e-01],\n",
       "          [ 8.5717e-02,  4.5655e-01,  1.9315e-01,  ..., -8.9393e-03,\n",
       "           -2.4954e-02,  2.6318e-01],\n",
       "          [-1.0452e-01,  1.0885e-01,  9.7673e-02,  ...,  1.6554e-01,\n",
       "            2.9402e-01,  4.3063e-02]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10, \n",
    "                       kernel_size=3, \n",
    "                       stride=1, padding=0)\n",
    "\n",
    "# Pass the data through the conv layer\n",
    "conv_output = conv_layer(test_image.unsqueeze(0))\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Stepping through the CNN `nn.MaxPool2d()`\n",
    "\n",
    "Max pooling is a technique used to downsample the image. It takes the maximum value from a region of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([3, 64, 64])\n",
      "Test image unsqueezed shape: torch.Size([1, 3, 64, 64])\n",
      "Max pool output shape: torch.Size([1, 10, 31, 31])\n",
      "Random tensor: tensor([[[[0.8823, 0.9150],\n",
      "          [0.3829, 0.9593]]]])\n",
      "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
      "Max pool tensor: tensor([[[[0.9593]]]])\n",
      "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Printing the shapes\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image unsqueezed shape: {test_image.unsqueeze(0).shape}\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a random tensor\n",
    "random_tensor = torch.rand(size=(1, 1, 2, 2)).to(device)\n",
    "\n",
    "# Create a sample nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Pass the data through the max pool layer\n",
    "max_pool_output = max_pool_layer(conv_output)\n",
    "print(f\"Max pool output shape: {max_pool_output.shape}\")\n",
    "\n",
    "# Pass the random tensor through the max pool layer\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "print(f\"Random tensor: {random_tensor}\")\n",
    "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
    "print(f\"Max pool tensor: {max_pool_tensor}\")\n",
    "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Instantiate the model\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, \n",
    "                              hidden_units=10, # Copilot is suggesting hidden_units=32, instead of 10. Following the tutorial\n",
    "                              output_shape=len(class_names)).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f551d0d9ca0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.8538,  -6.2179,  -7.2606,  -2.3967, -10.4100,   3.9492,  -4.9240,\n",
       "           8.7737,   2.1163,  17.7866]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the image through the model\n",
    "model_2_output = model_2(image.unsqueeze(0))\n",
    "model_2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting label from the model output\n",
    "model_2_output.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Setup the loss function, optimizer and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.1621,  0.1370, -0.1683],\n",
       "                        [ 0.5462,  0.3607,  0.0495],\n",
       "                        [-0.6471,  0.1970,  0.4676]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5746,  0.4838,  0.2621],\n",
       "                        [-0.3880,  1.0881, -0.0220],\n",
       "                        [-0.7000,  0.5108,  0.0685]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.5058, -0.0155,  0.2536],\n",
       "                        [-1.7606, -1.5033,  0.4640],\n",
       "                        [-1.4494, -0.7838,  0.2031]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0117, -0.7492, -0.9008],\n",
       "                        [ 0.8807, -0.7148,  0.1831],\n",
       "                        [ 0.4488, -0.1109,  0.5958]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0024,  0.2925,  0.3026],\n",
       "                        [ 0.4116,  0.5447, -1.0545],\n",
       "                        [ 0.1557,  0.3633, -0.3080]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1372,  0.1849,  0.0593],\n",
       "                        [ 0.1841, -0.1942, -0.3335],\n",
       "                        [-0.1307, -0.2554,  0.2667]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1676,  0.2785,  0.4344],\n",
       "                        [ 0.3183, -0.2479, -0.7091],\n",
       "                        [-0.0909, -0.8446, -0.4829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0861,  0.1070, -0.0309],\n",
       "                        [ 0.3518, -0.2454, -0.2299],\n",
       "                        [-0.2812,  0.2480,  0.0652]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.8877, -0.6221, -0.7425],\n",
       "                        [-0.2305, -0.9255, -0.1677],\n",
       "                        [ 0.6193,  0.5914, -0.2931]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2262,  0.1768, -0.1352],\n",
       "                        [ 0.2068, -0.0785,  0.1916],\n",
       "                        [-0.2585, -0.1682,  0.1018]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([-0.3192, -0.1102,  0.3364,  0.1221, -0.1249, -0.1901,  0.3314, -0.0644,\n",
       "                      -0.2084, -0.3206])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-6.9156e-02,  1.5792e-02, -1.8274e-02],\n",
       "                        [-8.8913e-02, -5.2318e-03, -7.8387e-02],\n",
       "                        [-1.0781e-01, -5.9351e-02, -9.4566e-02]],\n",
       "              \n",
       "                       [[-6.8722e-02,  9.8520e-02,  8.8698e-03],\n",
       "                        [ 2.9445e-02, -9.8875e-02, -8.6999e-02],\n",
       "                        [-3.7756e-02,  1.7379e-02, -1.0393e-01]],\n",
       "              \n",
       "                       [[-4.9420e-02, -5.5298e-02, -2.2518e-02],\n",
       "                        [-4.7129e-02, -1.0842e-02, -1.0452e-01],\n",
       "                        [-8.0134e-02, -6.3535e-02, -6.6070e-02]],\n",
       "              \n",
       "                       [[-8.3976e-02,  6.8073e-02, -3.0618e-02],\n",
       "                        [ 5.7005e-02,  1.6463e-02, -1.0336e-01],\n",
       "                        [ 5.9297e-02, -4.4633e-02, -4.7777e-02]],\n",
       "              \n",
       "                       [[-1.0290e-01, -1.0495e-01,  3.0862e-02],\n",
       "                        [-3.9729e-02,  4.4191e-02, -8.3620e-02],\n",
       "                        [ 6.0801e-02, -8.1546e-02, -1.8102e-02]],\n",
       "              \n",
       "                       [[ 2.2011e-02,  5.4473e-02,  8.5250e-02],\n",
       "                        [ 9.6092e-02, -8.3296e-02,  2.6526e-02],\n",
       "                        [-4.5281e-02, -1.1544e-02, -7.8916e-02]],\n",
       "              \n",
       "                       [[ 8.1611e-02, -9.2622e-02,  3.9657e-02],\n",
       "                        [ 1.3015e-02,  1.2330e-02, -8.3197e-02],\n",
       "                        [ 7.4835e-02, -4.2511e-03, -2.3489e-02]],\n",
       "              \n",
       "                       [[-9.2987e-02,  4.4050e-02, -1.5620e-02],\n",
       "                        [-4.9315e-02,  9.0571e-02,  2.3327e-02],\n",
       "                        [-6.0092e-02, -5.3333e-02, -5.1344e-03]],\n",
       "              \n",
       "                       [[ 5.6343e-02, -2.8865e-02, -5.8547e-02],\n",
       "                        [-3.0954e-02, -8.3793e-02,  4.1401e-02],\n",
       "                        [ 8.3591e-02, -1.0177e-01,  2.6408e-02]],\n",
       "              \n",
       "                       [[ 5.4454e-02,  1.9111e-02, -3.7537e-02],\n",
       "                        [ 5.5023e-02,  5.5394e-02,  3.9418e-02],\n",
       "                        [-1.8523e-02, -2.7910e-02,  1.1282e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1440e-01, -5.3197e-02,  5.4678e-02],\n",
       "                        [ 1.2823e-01,  4.3584e-03,  1.5622e-02],\n",
       "                        [ 6.1160e-02, -4.9896e-03,  1.2037e-01]],\n",
       "              \n",
       "                       [[-1.2441e-01, -9.8261e-02, -1.4778e-01],\n",
       "                        [ 7.7576e-02,  1.1188e-01, -5.1120e-02],\n",
       "                        [-2.0268e-01, -7.3399e-02, -1.8775e-01]],\n",
       "              \n",
       "                       [[-6.2270e-02,  1.6720e-02,  6.4443e-02],\n",
       "                        [ 3.2954e-02, -9.4350e-02, -6.2308e-02],\n",
       "                        [-1.6857e-02,  9.8848e-02,  1.3145e-02]],\n",
       "              \n",
       "                       [[-3.1611e-02, -1.7137e-02, -9.4442e-02],\n",
       "                        [ 6.7961e-02,  1.0515e-01, -9.9483e-02],\n",
       "                        [-7.3347e-02, -1.3608e-01,  1.1261e-01]],\n",
       "              \n",
       "                       [[ 7.7894e-03,  3.4648e-04,  8.0318e-02],\n",
       "                        [-8.2876e-02, -5.5509e-02,  3.5403e-01],\n",
       "                        [ 9.8373e-02,  1.3021e-01,  2.0321e-01]],\n",
       "              \n",
       "                       [[ 2.5868e-02, -1.2556e-03, -8.0150e-02],\n",
       "                        [-9.1123e-02, -9.8591e-02,  4.3099e-02],\n",
       "                        [-5.1933e-02, -2.1161e-02, -6.2024e-02]],\n",
       "              \n",
       "                       [[-2.3702e-02, -1.2095e-01, -1.3623e-01],\n",
       "                        [ 1.4205e-02, -7.8810e-02,  4.0729e-02],\n",
       "                        [-3.0632e-02, -1.0621e-01,  1.5372e-03]],\n",
       "              \n",
       "                       [[-5.2388e-02, -3.3412e-02, -9.9291e-02],\n",
       "                        [ 6.6104e-02, -6.5789e-02,  5.6502e-02],\n",
       "                        [ 4.6386e-02,  7.3941e-02, -7.6055e-02]],\n",
       "              \n",
       "                       [[ 1.0630e-01, -4.2976e-02,  5.2306e-02],\n",
       "                        [ 9.4876e-02, -2.6200e-02, -1.4791e-02],\n",
       "                        [-2.8417e-02, -9.3046e-02,  3.2344e-02]],\n",
       "              \n",
       "                       [[-1.0463e-01,  6.5453e-02,  7.8861e-02],\n",
       "                        [ 9.9641e-02, -2.4845e-02, -8.6601e-02],\n",
       "                        [ 2.3655e-02,  5.8250e-02, -1.0491e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3688e-02, -6.5612e-02, -9.0389e-03],\n",
       "                        [-7.8998e-02, -4.9239e-02, -3.6182e-02],\n",
       "                        [-1.4380e-01,  6.1401e-02,  8.0101e-02]],\n",
       "              \n",
       "                       [[-1.9183e-02, -8.8729e-03, -4.3393e-02],\n",
       "                        [-9.9471e-02, -1.0333e-01,  3.1591e-02],\n",
       "                        [-6.3664e-02, -7.4710e-02, -1.6119e-02]],\n",
       "              \n",
       "                       [[-3.5664e-02, -2.4786e-02, -1.2948e-02],\n",
       "                        [-2.2331e-02, -2.9799e-02, -6.3225e-02],\n",
       "                        [-8.5739e-02,  9.1600e-02, -4.8558e-02]],\n",
       "              \n",
       "                       [[ 2.1400e-02, -6.0233e-02, -3.7267e-04],\n",
       "                        [ 6.5451e-02,  5.6625e-03, -1.1299e-01],\n",
       "                        [ 1.2798e-02,  4.1783e-02, -5.7808e-03]],\n",
       "              \n",
       "                       [[ 4.2335e-02,  9.3549e-02, -1.7694e-02],\n",
       "                        [-1.8873e-02, -8.9242e-02, -2.6864e-02],\n",
       "                        [ 3.4053e-02,  3.1450e-02, -7.8528e-02]],\n",
       "              \n",
       "                       [[-8.4517e-02, -7.2103e-02, -1.0403e-01],\n",
       "                        [-8.1327e-02, -2.6065e-02,  7.1174e-02],\n",
       "                        [ 1.7635e-02, -8.0160e-02, -8.4483e-02]],\n",
       "              \n",
       "                       [[ 4.2856e-02, -9.4776e-02, -2.8115e-02],\n",
       "                        [ 4.3960e-02, -6.6332e-02, -2.5215e-02],\n",
       "                        [-1.7488e-02, -3.1407e-02, -6.2858e-02]],\n",
       "              \n",
       "                       [[-9.2915e-02, -8.5162e-02, -5.6706e-02],\n",
       "                        [ 9.7975e-02, -5.0180e-02, -7.1363e-02],\n",
       "                        [ 2.4602e-02,  2.5765e-02,  5.6763e-02]],\n",
       "              \n",
       "                       [[ 8.0782e-02,  5.4374e-02, -1.0438e-01],\n",
       "                        [ 1.1962e-02,  5.5452e-02, -1.0181e-02],\n",
       "                        [-6.2505e-02,  8.2501e-02, -4.8069e-02]],\n",
       "              \n",
       "                       [[-6.0014e-02, -9.5032e-02,  4.6965e-03],\n",
       "                        [ 4.6710e-02,  2.3334e-02,  2.0845e-02],\n",
       "                        [-7.9941e-02, -9.8440e-02,  1.8503e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2327e-01, -3.7627e-01, -1.5897e-01],\n",
       "                        [ 1.1515e-01,  2.3407e-02,  1.8319e-01],\n",
       "                        [ 3.3993e-01,  2.5448e-01,  1.8360e-01]],\n",
       "              \n",
       "                       [[-3.5688e-01,  1.9491e-01, -5.4836e-02],\n",
       "                        [ 7.0936e-02, -6.7884e-02,  1.7324e-01],\n",
       "                        [ 4.0737e-01, -3.2038e-01, -4.6435e-02]],\n",
       "              \n",
       "                       [[-1.6177e-01, -3.6897e-01, -3.1715e-01],\n",
       "                        [-4.6866e-01, -4.4284e-01, -1.4559e-01],\n",
       "                        [-2.3016e-02, -2.1320e-01,  4.0014e-02]],\n",
       "              \n",
       "                       [[-1.5892e-01, -4.8410e-02, -2.1176e-02],\n",
       "                        [ 1.1153e-02,  2.9146e-01,  1.6501e-01],\n",
       "                        [ 7.1006e-02, -1.7726e-01, -2.3752e-01]],\n",
       "              \n",
       "                       [[-5.4970e-01, -4.9996e-01, -1.2993e-01],\n",
       "                        [ 1.0100e-01,  1.4321e-01,  3.1419e-01],\n",
       "                        [ 7.8687e-02,  2.8486e-01,  1.5615e-01]],\n",
       "              \n",
       "                       [[-6.0496e-02, -4.3041e-02,  3.6321e-02],\n",
       "                        [-6.3805e-02, -6.9146e-02, -9.2770e-03],\n",
       "                        [-3.5461e-02, -8.9945e-02,  5.7300e-02]],\n",
       "              \n",
       "                       [[ 1.1311e-01, -1.1561e-01, -5.7712e-02],\n",
       "                        [-3.9045e-01, -1.9063e-01, -1.8150e-01],\n",
       "                        [ 2.2701e-01,  1.8514e-01, -1.4051e-01]],\n",
       "              \n",
       "                       [[-3.5841e-03, -1.2052e-01,  7.0452e-02],\n",
       "                        [-7.0674e-02, -5.0115e-02, -2.4736e-02],\n",
       "                        [ 5.1958e-03, -8.4847e-02,  3.1537e-02]],\n",
       "              \n",
       "                       [[-1.1984e-01, -1.9065e-02, -9.6996e-02],\n",
       "                        [-1.3602e-01, -6.4153e-02, -3.6130e-02],\n",
       "                        [-9.2367e-02, -1.2014e-01, -2.0262e-01]],\n",
       "              \n",
       "                       [[-1.0402e-01, -8.6303e-02,  2.0405e-02],\n",
       "                        [ 2.8126e-02,  2.2419e-02, -2.8073e-02],\n",
       "                        [ 9.7758e-02,  1.5019e-02, -6.2142e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2610e-02, -1.3790e-01,  1.0285e-01],\n",
       "                        [-1.8064e-01,  1.1676e-01, -2.4351e-02],\n",
       "                        [-3.8207e-01,  1.5125e-01,  3.1129e-01]],\n",
       "              \n",
       "                       [[-3.2928e-02,  4.2117e-01, -1.3157e-01],\n",
       "                        [ 5.9193e-01, -1.2557e-02, -8.8765e-03],\n",
       "                        [ 2.2603e-01, -1.5685e-01,  8.1374e-02]],\n",
       "              \n",
       "                       [[ 1.7476e-01, -3.8983e-01, -4.3578e-01],\n",
       "                        [ 3.9686e-01, -3.0339e-01, -8.3770e-02],\n",
       "                        [ 1.7341e-01, -2.4052e-01,  2.5806e-01]],\n",
       "              \n",
       "                       [[-2.9346e-01,  1.1846e-01,  2.8567e-01],\n",
       "                        [-3.3898e-01,  5.4839e-02, -1.6410e-03],\n",
       "                        [-2.2680e-01,  2.9399e-02, -6.8438e-02]],\n",
       "              \n",
       "                       [[-2.4916e-01,  1.4457e-01, -3.7709e-01],\n",
       "                        [-5.4589e-02,  1.5821e-01, -2.8264e-02],\n",
       "                        [-1.4629e-03, -1.2867e-01,  7.9926e-02]],\n",
       "              \n",
       "                       [[ 5.0474e-02, -7.7664e-02, -6.3619e-02],\n",
       "                        [-1.8740e-02, -2.3984e-02,  3.5710e-03],\n",
       "                        [-9.3140e-02,  2.9725e-02, -8.7418e-02]],\n",
       "              \n",
       "                       [[ 1.1386e-02,  8.1169e-03,  2.2407e-01],\n",
       "                        [-3.1846e-01,  1.3412e-01, -2.0090e-01],\n",
       "                        [-3.8978e-02,  1.4470e-02, -1.2420e-01]],\n",
       "              \n",
       "                       [[ 5.4908e-03,  1.8586e-02, -1.2435e-01],\n",
       "                        [-7.3831e-04, -2.4431e-02, -4.1322e-04],\n",
       "                        [ 6.6005e-03,  4.3603e-02, -5.5536e-02]],\n",
       "              \n",
       "                       [[-2.1682e-01,  7.8079e-02, -1.6744e-01],\n",
       "                        [-1.1530e-01, -3.3033e-01, -3.3424e-01],\n",
       "                        [-1.0962e-01,  1.1213e-01, -1.2393e-01]],\n",
       "              \n",
       "                       [[-7.4132e-03, -2.3676e-02,  1.9390e-02],\n",
       "                        [ 9.8722e-02,  1.1078e-02,  6.2048e-02],\n",
       "                        [ 8.2220e-02,  8.5854e-02, -3.6370e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2860e-03,  3.3427e-03, -1.5133e-01],\n",
       "                        [ 3.1354e-02, -5.5246e-03, -1.4782e-01],\n",
       "                        [ 5.6089e-02, -2.8555e-02, -1.6980e-01]],\n",
       "              \n",
       "                       [[ 1.2321e-01,  1.8005e-01,  6.0676e-01],\n",
       "                        [ 1.0995e-01, -3.5869e-01, -4.7122e-01],\n",
       "                        [-1.4013e-01, -2.8525e-01, -3.3455e-01]],\n",
       "              \n",
       "                       [[-2.2807e-01, -2.4602e-01, -9.1087e-02],\n",
       "                        [-3.4353e-01, -3.0092e-01,  3.6127e-01],\n",
       "                        [-7.5306e-02, -2.1751e-01,  2.4736e-01]],\n",
       "              \n",
       "                       [[-9.2940e-02, -5.5336e-02, -3.9698e-01],\n",
       "                        [-6.2140e-02, -2.7205e-01, -4.7793e-01],\n",
       "                        [ 5.5301e-01,  7.5797e-02,  2.6530e-01]],\n",
       "              \n",
       "                       [[-1.6146e-01, -9.1307e-02, -2.1618e-01],\n",
       "                        [ 3.4752e-01,  3.9148e-01, -5.1304e-02],\n",
       "                        [-9.8836e-02,  1.2147e-01, -3.9291e-01]],\n",
       "              \n",
       "                       [[-8.3379e-02, -6.9037e-03, -9.1667e-02],\n",
       "                        [ 7.3146e-02,  1.3126e-02, -4.9430e-02],\n",
       "                        [ 5.5811e-02, -9.7625e-02, -3.7909e-02]],\n",
       "              \n",
       "                       [[-2.5230e-01, -1.9753e-01, -1.2829e-01],\n",
       "                        [ 1.8998e-01,  4.1984e-01,  2.6013e-01],\n",
       "                        [ 3.4275e-01,  3.5458e-02, -1.4133e-01]],\n",
       "              \n",
       "                       [[ 9.9419e-02,  3.6544e-02,  6.6863e-03],\n",
       "                        [ 1.9037e-04, -8.3445e-02, -3.1816e-02],\n",
       "                        [ 9.6266e-02, -1.1522e-02,  2.0600e-02]],\n",
       "              \n",
       "                       [[-2.1764e-01, -4.1121e-02, -1.3104e-01],\n",
       "                        [-8.2310e-02,  2.9243e-02, -1.6109e-01],\n",
       "                        [-1.9546e-01, -2.8453e-03, -3.3544e-03]],\n",
       "              \n",
       "                       [[-5.1471e-02,  4.0166e-02,  8.3499e-02],\n",
       "                        [-2.8790e-02, -4.3321e-02, -9.4950e-02],\n",
       "                        [-5.4561e-02, -9.2331e-02, -2.4155e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8058e-01, -1.8528e-01, -5.9141e-02],\n",
       "                        [ 4.7997e-01, -9.0701e-02, -6.8236e-01],\n",
       "                        [-1.9069e-02,  2.9881e-01, -2.2329e-01]],\n",
       "              \n",
       "                       [[-2.6218e-02, -2.8850e-02, -1.3875e-01],\n",
       "                        [ 9.8092e-02,  3.8804e-02, -6.2324e-01],\n",
       "                        [-1.7778e-02,  1.8613e-01, -2.4930e-01]],\n",
       "              \n",
       "                       [[ 1.3059e-02,  2.9113e-01,  3.1378e-01],\n",
       "                        [-1.5485e-01,  1.6426e-03,  6.0568e-01],\n",
       "                        [-9.7927e-02,  9.4288e-04,  6.1184e-02]],\n",
       "              \n",
       "                       [[-5.2670e-02, -1.5149e-01, -3.7444e-01],\n",
       "                        [-1.8378e-02, -2.6924e-02,  1.1429e-01],\n",
       "                        [-1.1602e-01,  1.3209e-01,  6.5659e-01]],\n",
       "              \n",
       "                       [[ 2.1572e-01,  3.6021e-01, -5.0468e-01],\n",
       "                        [ 3.6424e-01,  6.1177e-01, -6.4784e-01],\n",
       "                        [-2.5626e-01,  1.9520e-01, -2.7933e-01]],\n",
       "              \n",
       "                       [[ 9.4063e-02, -8.9765e-02, -2.3447e-02],\n",
       "                        [-9.2117e-02, -3.9243e-02,  3.7563e-02],\n",
       "                        [ 1.0241e-01,  1.7439e-02,  1.0717e-01]],\n",
       "              \n",
       "                       [[ 1.1139e-02,  3.2490e-01,  5.8381e-01],\n",
       "                        [ 3.7793e-01,  1.9533e-01,  2.4168e-01],\n",
       "                        [-2.6289e-02, -2.4365e-01, -4.3064e-01]],\n",
       "              \n",
       "                       [[-9.3493e-02,  6.4045e-02, -5.6699e-02],\n",
       "                        [ 1.1173e-01,  9.6423e-02, -8.6207e-02],\n",
       "                        [-1.4294e-02,  2.1721e-02,  6.3837e-02]],\n",
       "              \n",
       "                       [[ 2.0627e-02, -3.7203e-01,  8.8701e-02],\n",
       "                        [ 8.3534e-02,  3.7068e-01, -8.6938e-02],\n",
       "                        [ 1.1414e-01,  1.7129e-01,  2.7417e-01]],\n",
       "              \n",
       "                       [[ 5.9465e-02,  3.8344e-02,  8.2932e-02],\n",
       "                        [-3.9583e-02,  3.5369e-02,  3.7387e-02],\n",
       "                        [-8.7627e-02, -1.0241e-01, -5.4791e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5699e-01, -7.0751e-02, -4.8793e-01],\n",
       "                        [ 3.9739e-01,  1.0834e-02, -1.9713e-01],\n",
       "                        [ 5.7714e-02,  4.1011e-01, -3.3367e-01]],\n",
       "              \n",
       "                       [[ 3.1041e-01,  5.2008e-02, -4.4366e-01],\n",
       "                        [ 3.8624e-02,  3.7123e-01, -7.6050e-01],\n",
       "                        [-5.1254e-03,  3.8795e-01, -8.4846e-01]],\n",
       "              \n",
       "                       [[-4.8919e-01, -1.6411e-01, -2.8052e-02],\n",
       "                        [-2.3673e-01, -2.2465e-01, -6.1468e-02],\n",
       "                        [-8.0185e-02, -2.9362e-01, -5.5692e-02]],\n",
       "              \n",
       "                       [[ 6.2512e-02, -3.7680e-01,  1.0819e-01],\n",
       "                        [ 9.7856e-02, -3.3969e-01,  6.3034e-01],\n",
       "                        [-3.1692e-01,  1.7027e-01,  2.1792e-02]],\n",
       "              \n",
       "                       [[-1.2707e-01,  3.0821e-01, -4.5174e-01],\n",
       "                        [-1.2889e-01,  9.4710e-01, -3.6581e-01],\n",
       "                        [ 4.5081e-02,  3.5470e-01, -3.4264e-01]],\n",
       "              \n",
       "                       [[-2.2244e-02, -7.1637e-02,  4.5085e-03],\n",
       "                        [ 1.1406e-02, -1.4226e-02,  5.6331e-03],\n",
       "                        [-4.1705e-02,  2.6298e-02,  4.4001e-02]],\n",
       "              \n",
       "                       [[-8.5194e-03,  1.2018e-01, -4.4004e-02],\n",
       "                        [-1.2643e-01,  2.0663e-01,  5.8826e-02],\n",
       "                        [-2.3360e-01,  2.8034e-01,  4.8064e-02]],\n",
       "              \n",
       "                       [[-1.0637e-01,  5.1386e-02, -6.7973e-02],\n",
       "                        [-7.8150e-02, -4.9441e-02, -6.7103e-02],\n",
       "                        [ 8.4962e-02, -6.3129e-02,  1.7808e-02]],\n",
       "              \n",
       "                       [[-1.6533e-01,  1.7724e-01, -3.3453e-01],\n",
       "                        [-2.3559e-01, -1.2000e-01, -1.6649e-01],\n",
       "                        [ 8.8374e-02, -1.7317e-01, -5.2488e-01]],\n",
       "              \n",
       "                       [[ 2.0587e-02,  2.8548e-02,  4.0580e-02],\n",
       "                        [ 5.7752e-02, -2.3799e-02,  5.9138e-02],\n",
       "                        [ 7.7660e-02, -2.6900e-02,  7.4793e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2169e-02, -1.1868e-01,  5.0134e-02],\n",
       "                        [ 1.1369e-01,  1.8408e-01, -3.1768e-02],\n",
       "                        [ 1.5946e-01, -2.5779e-01, -2.3301e-01]],\n",
       "              \n",
       "                       [[-1.5546e-01,  3.9490e-02, -2.1346e-01],\n",
       "                        [ 8.5878e-02, -5.3795e-02, -4.9047e-01],\n",
       "                        [-2.9337e-01, -2.3235e-01,  3.3881e-02]],\n",
       "              \n",
       "                       [[ 3.4796e-02, -5.8558e-01, -5.9077e-01],\n",
       "                        [-4.2601e-01, -4.7364e-01, -4.6177e-01],\n",
       "                        [-7.5589e-02, -2.5962e-01,  3.4415e-02]],\n",
       "              \n",
       "                       [[ 2.2457e-01,  7.9933e-02,  2.0886e-01],\n",
       "                        [-3.4913e-01,  7.7407e-02, -3.3373e-02],\n",
       "                        [-3.9127e-01,  4.4948e-02, -5.2194e-02]],\n",
       "              \n",
       "                       [[-1.1093e-01,  3.8037e-01,  7.1857e-02],\n",
       "                        [ 4.9801e-01,  2.1775e-01, -3.6198e-03],\n",
       "                        [ 1.3078e-01, -3.7270e-01, -5.4463e-01]],\n",
       "              \n",
       "                       [[ 9.2689e-02,  8.2827e-02,  2.7314e-02],\n",
       "                        [-4.4575e-03, -9.7282e-02, -2.2592e-02],\n",
       "                        [ 9.2335e-02,  1.5537e-02,  1.3650e-02]],\n",
       "              \n",
       "                       [[ 6.5772e-02,  1.3642e-01,  2.2240e-01],\n",
       "                        [ 1.7414e-01,  1.7378e-01,  7.6203e-02],\n",
       "                        [ 6.3292e-02, -1.1934e-01,  2.0452e-02]],\n",
       "              \n",
       "                       [[-6.7330e-02,  3.6470e-02,  9.6604e-02],\n",
       "                        [ 4.8054e-02, -1.0472e-01, -1.0132e-01],\n",
       "                        [ 3.4363e-02, -4.5840e-02, -3.9007e-02]],\n",
       "              \n",
       "                       [[-2.0458e-01, -3.0498e-01,  9.7363e-02],\n",
       "                        [-2.0530e-02, -1.9999e-01, -3.7678e-01],\n",
       "                        [ 1.1038e-01, -1.5103e-01, -1.2858e-01]],\n",
       "              \n",
       "                       [[ 5.5862e-02,  9.5178e-02,  2.2884e-04],\n",
       "                        [ 2.0664e-02,  3.8779e-02, -9.9646e-02],\n",
       "                        [ 9.4973e-03, -6.7182e-03, -5.9061e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5122e-01,  3.9939e-01,  2.6264e-01],\n",
       "                        [-2.4723e-02,  2.9586e-01,  1.5676e-01],\n",
       "                        [-6.8023e-01, -3.8217e-01, -2.1188e-01]],\n",
       "              \n",
       "                       [[ 1.3180e-01,  1.6406e-01, -1.3455e-01],\n",
       "                        [ 1.9247e-02,  2.2213e-01, -4.1796e-02],\n",
       "                        [-4.6481e-01, -1.7547e-01, -1.2650e-01]],\n",
       "              \n",
       "                       [[-9.7549e-02, -3.3377e-01, -1.6806e-01],\n",
       "                        [ 3.1658e-02, -1.1181e-01, -2.9571e-01],\n",
       "                        [ 1.6448e-01,  2.2505e-01,  2.8123e-01]],\n",
       "              \n",
       "                       [[ 2.7110e-01,  9.3144e-02,  2.4260e-02],\n",
       "                        [-3.1936e-01, -3.0061e-01, -8.4943e-02],\n",
       "                        [-1.7253e-01, -4.5026e-01, -4.3705e-01]],\n",
       "              \n",
       "                       [[ 6.1120e-01,  4.2716e-01,  1.3370e-01],\n",
       "                        [-5.8913e-03, -3.1661e-02,  1.0183e-02],\n",
       "                        [-1.3510e-01, -4.5288e-01, -2.1530e-01]],\n",
       "              \n",
       "                       [[-1.0111e-01, -7.5899e-02, -4.0114e-02],\n",
       "                        [ 8.2522e-02,  1.3826e-02, -7.7416e-02],\n",
       "                        [ 4.3453e-03, -8.1281e-02, -2.0259e-02]],\n",
       "              \n",
       "                       [[ 1.1477e-02,  3.1995e-02, -1.0231e-01],\n",
       "                        [ 1.0389e-01,  7.5749e-02, -7.9140e-02],\n",
       "                        [ 3.6018e-01,  1.3529e-01, -1.7319e-01]],\n",
       "              \n",
       "                       [[-2.1407e-02,  6.9028e-02, -3.6498e-02],\n",
       "                        [-6.3167e-02,  7.4421e-02,  8.7251e-02],\n",
       "                        [ 1.0226e-01,  4.6711e-02, -2.2490e-02]],\n",
       "              \n",
       "                       [[ 1.8394e-01,  2.5186e-01, -1.2286e-01],\n",
       "                        [ 1.3735e-01, -7.7451e-02, -1.1598e-01],\n",
       "                        [ 9.6499e-02,  6.3675e-02, -8.4985e-02]],\n",
       "              \n",
       "                       [[ 4.7007e-02, -1.7729e-02, -8.8433e-02],\n",
       "                        [ 8.4501e-02, -5.3204e-02, -1.1380e-02],\n",
       "                        [ 1.0091e-02, -6.3807e-03, -9.9036e-02]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([-0.0048, -0.1634, -0.1039,  0.6113,  0.1195,  0.3273, -0.2911, -0.1274,\n",
       "                       0.3605,  0.1164])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 0.0251, -0.0869, -0.0701],\n",
       "                        [-0.0039,  0.0143,  0.0647],\n",
       "                        [-0.0775,  0.0287,  0.0669]],\n",
       "              \n",
       "                       [[ 0.0220, -0.1555, -0.0337],\n",
       "                        [-0.1370, -0.1228,  0.0073],\n",
       "                        [-0.0389,  0.0168, -0.1095]],\n",
       "              \n",
       "                       [[ 0.0143, -0.0650,  0.0511],\n",
       "                        [-0.0460, -0.0287, -0.0939],\n",
       "                        [ 0.0010,  0.0990,  0.0524]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1641, -0.1501,  0.0706],\n",
       "                        [-0.2613, -0.0537,  0.0182],\n",
       "                        [ 0.0169,  0.1319,  0.0203]],\n",
       "              \n",
       "                       [[-0.2693, -0.4893,  0.0315],\n",
       "                        [-0.1129,  0.3718,  0.3966],\n",
       "                        [-0.0012,  0.1147, -0.1602]],\n",
       "              \n",
       "                       [[-0.0012, -0.1793, -0.1058],\n",
       "                        [-0.0582, -0.1476,  0.1750],\n",
       "                        [-0.0998, -0.0923, -0.0262]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0728,  0.0611, -0.0614],\n",
       "                        [ 0.1018, -0.0455,  0.0681],\n",
       "                        [ 0.0187,  0.0234, -0.0234]],\n",
       "              \n",
       "                       [[ 0.0247, -0.0179, -0.1530],\n",
       "                        [-0.0995,  0.1053, -0.0630],\n",
       "                        [ 0.0029, -0.0556,  0.0532]],\n",
       "              \n",
       "                       [[ 0.0638,  0.0357, -0.0501],\n",
       "                        [-0.0864,  0.0041, -0.0579],\n",
       "                        [ 0.0869, -0.1008,  0.0523]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1050,  0.0015,  0.1061],\n",
       "                        [-0.4351, -0.0561,  0.1171],\n",
       "                        [-0.0686, -0.1690,  0.0542]],\n",
       "              \n",
       "                       [[-0.1368, -0.1303,  0.2004],\n",
       "                        [-0.0975,  0.2757,  0.3258],\n",
       "                        [-0.1131, -0.0980, -0.2259]],\n",
       "              \n",
       "                       [[-0.1799, -0.3184, -0.2957],\n",
       "                        [ 0.1996,  0.1441,  0.1302],\n",
       "                        [-0.1122,  0.1295, -0.0457]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0339,  0.0823,  0.0928],\n",
       "                        [-0.0809, -0.0847, -0.0868],\n",
       "                        [-0.0622, -0.0463, -0.0065]],\n",
       "              \n",
       "                       [[-0.0097, -0.0446, -0.0641],\n",
       "                        [-0.0231,  0.1512, -0.0336],\n",
       "                        [-0.0747,  0.0492,  0.0234]],\n",
       "              \n",
       "                       [[ 0.0811,  0.0655,  0.0945],\n",
       "                        [-0.0770,  0.0674,  0.0861],\n",
       "                        [-0.0522,  0.0971,  0.0787]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0409,  0.1710,  0.2060],\n",
       "                        [-0.0316, -0.4021,  0.1029],\n",
       "                        [-0.1811, -0.8583,  0.2371]],\n",
       "              \n",
       "                       [[-0.1582, -0.0163,  0.2865],\n",
       "                        [ 0.2173, -0.0813,  0.4584],\n",
       "                        [ 0.2337, -0.4428, -0.0351]],\n",
       "              \n",
       "                       [[-0.0536, -0.2121, -0.2816],\n",
       "                        [-0.1134,  0.2893,  0.0066],\n",
       "                        [ 0.0456,  0.1033,  0.2831]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0879,  0.0843, -0.0690],\n",
       "                        [ 0.0801,  0.0421, -0.0104],\n",
       "                        [-0.0778, -0.0154, -0.0916]],\n",
       "              \n",
       "                       [[ 0.0434,  0.0962, -0.0634],\n",
       "                        [ 0.1128, -0.0711, -0.0413],\n",
       "                        [-0.0472,  0.0037,  0.0110]],\n",
       "              \n",
       "                       [[ 0.0475, -0.0012, -0.0518],\n",
       "                        [ 0.0749,  0.0729,  0.0162],\n",
       "                        [-0.0480,  0.0219,  0.0027]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0716,  0.0551, -0.2564],\n",
       "                        [ 0.1944, -0.2336, -0.3959],\n",
       "                        [-0.2928,  0.0528, -0.3099]],\n",
       "              \n",
       "                       [[-0.1729, -0.2130, -0.5460],\n",
       "                        [ 0.0960, -0.1039, -0.1677],\n",
       "                        [ 0.5112, -0.0565,  0.3732]],\n",
       "              \n",
       "                       [[-0.0927, -0.2059,  0.0092],\n",
       "                        [-0.1602,  0.0038, -0.1795],\n",
       "                        [ 0.1453,  0.1134, -0.0513]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0435, -0.0161,  0.0530],\n",
       "                        [ 0.0945, -0.0464, -0.0479],\n",
       "                        [ 0.0813,  0.0081, -0.0102]],\n",
       "              \n",
       "                       [[ 0.0538, -0.0725, -0.0379],\n",
       "                        [ 0.0586,  0.0304, -0.0968],\n",
       "                        [-0.0069, -0.1076, -0.1001]],\n",
       "              \n",
       "                       [[ 0.0671, -0.0286, -0.0546],\n",
       "                        [ 0.0071,  0.0253, -0.0657],\n",
       "                        [-0.0715, -0.1024,  0.0252]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0990,  0.0162,  0.1702],\n",
       "                        [-0.0025, -0.1128, -0.0018],\n",
       "                        [-0.4080,  0.0229,  0.0913]],\n",
       "              \n",
       "                       [[ 0.0504, -0.0032,  0.1809],\n",
       "                        [ 0.0121, -0.2752, -0.0123],\n",
       "                        [-0.3166, -0.4963,  0.1308]],\n",
       "              \n",
       "                       [[-0.2276,  0.1725,  0.1883],\n",
       "                        [-0.0113, -0.0262, -0.0095],\n",
       "                        [-0.0798, -0.1889, -0.2535]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0103,  0.0935,  0.0925],\n",
       "                        [-0.0527, -0.0031, -0.0501],\n",
       "                        [ 0.0335, -0.1035,  0.0339]],\n",
       "              \n",
       "                       [[-0.0107,  0.1851,  0.1100],\n",
       "                        [-0.0559,  0.1183, -0.0092],\n",
       "                        [-0.0762,  0.1711,  0.0450]],\n",
       "              \n",
       "                       [[ 0.0672, -0.0098,  0.0346],\n",
       "                        [-0.0551, -0.0379,  0.0442],\n",
       "                        [ 0.0463,  0.0422, -0.0980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.3112, -0.0952, -0.0613],\n",
       "                        [-0.9444,  0.0412,  0.0566],\n",
       "                        [-0.6098,  0.2820,  0.1680]],\n",
       "              \n",
       "                       [[-0.4259, -0.4556,  0.1603],\n",
       "                        [-0.5772,  0.5422,  0.3490],\n",
       "                        [ 0.1100,  0.0291, -0.0458]],\n",
       "              \n",
       "                       [[ 0.2242,  0.0418, -0.3080],\n",
       "                        [-0.0224, -0.1236,  0.1459],\n",
       "                        [ 0.1137,  0.2701, -0.1048]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([ 0.2642, -0.1709,  0.2113, -0.0057, -0.0759, -0.1154,  0.4951, -0.1336,\n",
       "                      -0.0542,  0.5109,  0.4817,  0.1222,  0.4823,  0.3004, -0.0825,  0.2526,\n",
       "                       0.4052,  0.0994,  0.9066,  0.5077])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[ 0.1773, -0.0340, -0.1108],\n",
       "                        [ 0.2999, -0.1379, -0.1168],\n",
       "                        [ 0.2532, -0.1063, -0.0503]],\n",
       "              \n",
       "                       [[-0.0797,  0.0609, -0.1566],\n",
       "                        [ 0.0366,  0.0594, -0.1795],\n",
       "                        [ 0.2782,  0.0549, -0.1569]],\n",
       "              \n",
       "                       [[-0.1057, -0.0565, -0.2174],\n",
       "                        [-0.0482, -0.2262, -0.1511],\n",
       "                        [ 0.0537, -0.2817, -0.2051]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0783, -0.2104, -0.0085],\n",
       "                        [ 0.0394,  0.0803,  0.1235],\n",
       "                        [-0.0924,  0.0882,  0.2034]],\n",
       "              \n",
       "                       [[ 0.1301,  0.0419,  0.0545],\n",
       "                        [-0.2234, -0.0778,  0.0529],\n",
       "                        [-0.1018, -0.0514,  0.0740]],\n",
       "              \n",
       "                       [[ 0.1809, -0.2692, -0.3228],\n",
       "                        [ 0.0789, -0.2183, -0.3768],\n",
       "                        [ 0.2920, -0.0109, -0.0984]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0465,  0.2646, -0.1305],\n",
       "                        [ 0.3908,  0.1007, -0.2731],\n",
       "                        [ 0.1071, -0.0874, -0.1581]],\n",
       "              \n",
       "                       [[-0.2668, -0.2380, -0.0450],\n",
       "                        [-0.1273,  0.1111,  0.0087],\n",
       "                        [-0.2072, -0.0559, -0.0783]],\n",
       "              \n",
       "                       [[-0.0654, -0.2431, -0.1246],\n",
       "                        [ 0.0920, -0.1418, -0.0469],\n",
       "                        [-0.2672, -0.1398, -0.0884]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1627, -0.2908,  0.0108],\n",
       "                        [-0.0430, -0.2291, -0.0327],\n",
       "                        [-0.0721,  0.1825,  0.0514]],\n",
       "              \n",
       "                       [[ 0.4475, -0.0761, -0.0425],\n",
       "                        [ 0.1308, -0.1547, -0.2001],\n",
       "                        [ 0.1898,  0.0153, -0.1093]],\n",
       "              \n",
       "                       [[-0.3486,  0.0994, -0.0586],\n",
       "                        [-0.1124, -0.0244, -0.1754],\n",
       "                        [-0.1282, -0.1851, -0.0989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1345, -0.2223,  0.0315],\n",
       "                        [-0.0181,  0.0438,  0.0919],\n",
       "                        [ 0.1109, -0.0223,  0.0286]],\n",
       "              \n",
       "                       [[ 0.0858, -0.0912, -0.0503],\n",
       "                        [-0.0103,  0.0171, -0.1367],\n",
       "                        [-0.0008, -0.0409,  0.0619]],\n",
       "              \n",
       "                       [[ 0.3159,  0.1249, -0.1114],\n",
       "                        [-0.0445, -0.1349, -0.1166],\n",
       "                        [-0.0341,  0.0152,  0.0330]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0746, -0.0582,  0.0592],\n",
       "                        [-0.0099, -0.1284, -0.1499],\n",
       "                        [-0.0170, -0.0277, -0.0308]],\n",
       "              \n",
       "                       [[ 0.1038,  0.2334, -0.0978],\n",
       "                        [ 0.0611, -0.0011,  0.0221],\n",
       "                        [ 0.0119, -0.0810,  0.0570]],\n",
       "              \n",
       "                       [[-0.0420, -0.4654, -0.0303],\n",
       "                        [-0.2756,  0.1338,  0.0958],\n",
       "                        [-0.0242,  0.3477, -0.0906]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0996, -0.0275, -0.0050],\n",
       "                        [-0.1023, -0.0610, -0.1219],\n",
       "                        [ 0.0255,  0.1801,  0.0439]],\n",
       "              \n",
       "                       [[-0.0165, -0.0362, -0.0009],\n",
       "                        [-0.0601, -0.1394,  0.1513],\n",
       "                        [-0.1211, -0.1192,  0.0069]],\n",
       "              \n",
       "                       [[ 0.1143, -0.0034, -0.1466],\n",
       "                        [-0.1411, -0.0083,  0.0184],\n",
       "                        [-0.0536, -0.1195, -0.1503]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0134, -0.0282, -0.0280],\n",
       "                        [-0.0799, -0.0598, -0.0118],\n",
       "                        [ 0.1051,  0.0958,  0.0536]],\n",
       "              \n",
       "                       [[ 0.1179,  0.0738, -0.0056],\n",
       "                        [ 0.0684,  0.0701, -0.1258],\n",
       "                        [ 0.0335,  0.0340,  0.1508]],\n",
       "              \n",
       "                       [[-0.0216, -0.2874, -0.1404],\n",
       "                        [-0.1592, -0.0899,  0.1839],\n",
       "                        [-0.0851, -0.1478, -0.0433]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0655,  0.1510,  0.1756],\n",
       "                        [-0.1993,  0.2324, -0.0929],\n",
       "                        [-0.0061, -0.1423, -0.1935]],\n",
       "              \n",
       "                       [[-0.0599, -0.0356,  0.0089],\n",
       "                        [-0.0324, -0.1675, -0.1425],\n",
       "                        [-0.2362, -0.0619, -0.1029]],\n",
       "              \n",
       "                       [[ 0.0625,  0.0321, -0.0069],\n",
       "                        [-0.2030, -0.3249,  0.0506],\n",
       "                        [-0.1785, -0.1688,  0.0591]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1486, -0.0750, -0.0335],\n",
       "                        [ 0.2091, -0.1722, -0.0082],\n",
       "                        [-0.1408,  0.0457,  0.1890]],\n",
       "              \n",
       "                       [[ 0.1093,  0.1471,  0.0477],\n",
       "                        [ 0.2370, -0.0810,  0.0649],\n",
       "                        [-0.0847, -0.3281, -0.0373]],\n",
       "              \n",
       "                       [[-0.2845, -0.2889,  0.1988],\n",
       "                        [-0.4516,  0.2331, -0.3584],\n",
       "                        [-0.0569,  0.0832, -0.2434]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0987, -0.2574,  0.0093],\n",
       "                        [-0.2227,  0.2087,  0.2034],\n",
       "                        [ 0.0203,  0.2969, -0.2243]],\n",
       "              \n",
       "                       [[-0.0256, -0.1026, -0.0845],\n",
       "                        [-0.1532,  0.0374, -0.0021],\n",
       "                        [-0.1801, -0.0423, -0.0882]],\n",
       "              \n",
       "                       [[ 0.0140,  0.0782, -0.0927],\n",
       "                        [-0.1842, -0.2195,  0.1604],\n",
       "                        [ 0.1285,  0.0811, -0.1097]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1764,  0.0491, -0.2021],\n",
       "                        [ 0.0121,  0.0565,  0.0542],\n",
       "                        [ 0.1536, -0.0457, -0.0327]],\n",
       "              \n",
       "                       [[ 0.3050,  0.2788,  0.2744],\n",
       "                        [-0.0879, -0.1822, -0.0997],\n",
       "                        [-0.0381, -0.1107, -0.1000]],\n",
       "              \n",
       "                       [[-0.3385, -0.5485, -0.0203],\n",
       "                        [-0.0507,  0.4015,  0.1268],\n",
       "                        [-0.0208,  0.3297, -0.0952]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([-0.4032,  0.1253, -0.3925,  0.3360,  0.0628,  0.1749,  0.8744, -0.2017,\n",
       "                      -0.0411,  0.0218,  0.1048,  0.1774,  0.2374,  0.3198,  0.1396, -0.0114,\n",
       "                      -0.0411, -0.3712,  0.2155, -0.1750])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[-0.0317, -0.0106, -0.0123,  ...,  0.0240,  0.0948,  0.1390],\n",
       "                      [ 0.0508,  0.0604,  0.0419,  ..., -0.0777, -0.0927, -0.0591],\n",
       "                      [-0.0121, -0.0540,  0.0946,  ..., -0.1025,  0.0375,  0.0445],\n",
       "                      ...,\n",
       "                      [-0.0208, -0.0443, -0.0013,  ..., -0.0544, -0.1429,  0.0134],\n",
       "                      [ 0.0160, -0.0038,  0.0946,  ..., -0.1888, -0.0920, -0.1762],\n",
       "                      [-0.0054, -0.0486, -0.0318,  ...,  0.1105,  0.0453,  0.0022]])),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.2863, -0.1871, -0.1102, -0.0424, -0.0441, -0.1233, -0.0098,  0.1849,\n",
       "                       0.0184, -0.0406,  0.2894,  0.1393,  0.0624, -0.0362, -0.0336,  0.1736,\n",
       "                       0.0565,  0.0198,  0.2282,  0.1522,  0.0470,  0.2250,  0.0256, -0.1660,\n",
       "                       0.0496, -0.0169, -0.0380,  0.0438, -0.1914,  0.3527,  0.2329,  0.2271,\n",
       "                      -0.0627, -0.0258,  0.1729,  0.0195,  0.0085,  0.0307,  0.2830, -0.1239])),\n",
       "             ('classifier.3.weight',\n",
       "              tensor([[-0.0967, -0.1317,  0.1170,  0.1893,  0.5387,  0.1987,  0.0516,  0.0275,\n",
       "                        0.4549, -0.1132,  0.7398,  0.1653,  0.3710, -0.3527,  0.0860,  0.1828,\n",
       "                        0.2986,  0.3307, -0.1619,  0.0446, -0.2213, -0.9032,  0.1117, -0.1768,\n",
       "                       -0.0932, -0.3931, -0.4786, -0.5323,  0.0703,  1.0319,  0.3078, -0.0394,\n",
       "                       -0.0756, -0.0422,  0.1800,  0.0077,  0.2103,  0.2556,  0.3696,  0.0726],\n",
       "                      [-0.3686, -0.0190, -0.2554, -0.0478, -0.0113, -0.0380,  0.0182,  0.1225,\n",
       "                        0.0410, -0.0531, -0.1549,  0.2001, -0.0518, -0.1634, -0.1517, -0.1120,\n",
       "                       -0.7038,  0.2862, -0.0076, -0.3707,  0.0284, -0.3474, -0.1126,  1.3563,\n",
       "                        0.1350,  0.0358, -0.1522,  0.2776, -0.1710,  0.0792, -0.1440,  0.4888,\n",
       "                        0.1165, -0.1836,  0.4429, -0.4860, -0.1940, -0.3162, -0.6230, -0.4126],\n",
       "                      [-0.1969, -0.1130,  0.1884, -0.1590,  0.1670, -0.1539, -0.0409, -0.0991,\n",
       "                       -0.0948, -0.2903,  0.3697, -0.2178,  0.0839,  0.1300, -0.0296,  0.6695,\n",
       "                        0.5941, -0.0848,  0.0770, -0.6135,  0.4664, -0.1982, -0.1437, -0.1459,\n",
       "                        0.0233,  0.1417, -0.2494, -0.1102, -0.1441, -0.2655,  0.5748,  0.0392,\n",
       "                        0.0535, -0.3427,  0.3593,  0.6746, -0.3316,  0.5013,  0.5337, -0.0553],\n",
       "                      [-0.3415,  0.0271, -0.1777,  0.3061, -0.1479, -0.2303,  0.1241,  0.6465,\n",
       "                        0.3028,  0.2063, -0.4673, -0.1891, -0.6221,  0.2093, -0.3663, -0.0330,\n",
       "                        0.3488, -0.1491, -0.1215, -0.2810, -0.3749,  0.4476,  0.0654,  0.0464,\n",
       "                       -0.0499, -0.4203,  0.2664,  0.4192, -0.4354,  0.5178, -0.2089,  0.3319,\n",
       "                       -0.1309, -0.3499, -0.1716, -0.4637,  0.1961,  0.2402,  0.4955,  0.1823],\n",
       "                      [-0.2063,  0.1077,  0.2328,  0.0917, -0.3214,  0.3175, -0.0202,  0.5803,\n",
       "                       -0.2214, -0.1850, -0.1165, -0.1066, -0.2616, -0.2327, -0.0401, -0.1053,\n",
       "                        0.8979, -0.3462, -0.5915, -0.5894,  0.3178, -0.6690,  0.0648,  0.2002,\n",
       "                       -0.1094,  0.2148,  0.1455,  0.0784, -0.4843, -0.2889,  0.1911, -0.1374,\n",
       "                        0.1469, -0.2113, -0.1789,  0.9417, -0.2159,  0.0176, -0.0322,  0.5041],\n",
       "                      [ 0.4101,  0.3079,  0.2039,  0.3424, -0.1933, -0.2712, -0.1642, -0.0606,\n",
       "                        0.2603, -0.0829,  0.1383, -0.6485, -0.1102, -0.0810, -0.1305, -0.5159,\n",
       "                       -0.9765,  0.0069, -0.1625,  0.3484, -0.0979,  0.3534, -0.2025, -0.2883,\n",
       "                        0.0254,  0.9612,  0.0708,  0.0036,  0.7292, -0.6347, -0.5348, -0.0964,\n",
       "                       -0.2429, -0.2145,  0.4344, -0.4888,  0.0630, -0.0079, -0.2242, -0.0685],\n",
       "                      [-0.5514,  0.4658, -0.3946, -0.4378, -0.1892,  0.0342,  0.1417,  0.0915,\n",
       "                       -0.2214,  0.4265,  0.4495, -0.3673,  0.4475,  0.2402,  0.0505,  0.4783,\n",
       "                        0.8884, -0.2291,  0.2833, -0.1960,  0.2672, -0.4421,  0.0552,  0.0172,\n",
       "                        0.0251, -0.2683,  0.6302, -0.3711, -0.2213,  0.8988, -0.2351, -0.5477,\n",
       "                        0.1249, -0.1271, -0.1587,  0.2475, -0.1275, -0.2402,  0.4749, -0.1389],\n",
       "                      [ 1.1429, -0.1397, -0.4599, -0.0208,  0.0881,  0.2652,  0.0261, -0.6744,\n",
       "                        0.0880, -0.1479, -0.5028,  0.0927,  0.1354,  0.2507,  0.1422, -0.1772,\n",
       "                       -0.8975, -0.1729,  0.7085,  0.2575, -0.1493,  0.7360, -0.0080, -0.2819,\n",
       "                       -0.1059,  0.2643, -0.2152, -0.2558, -0.0221, -0.4651,  0.5246, -0.3712,\n",
       "                       -0.1640,  0.0742, -0.6456, -0.5703, -0.2347, -0.0355, -0.4712,  0.0100],\n",
       "                      [-1.0048,  0.1900,  0.9270, -0.2976, -0.1647, -0.2439,  0.1228, -0.0871,\n",
       "                       -0.1081, -0.1744,  0.0895,  0.8753,  0.1582, -0.1759,  0.0726, -0.0386,\n",
       "                       -0.3273, -0.2764,  0.4047,  1.2483, -0.2035, -0.0719,  0.1247, -0.3711,\n",
       "                       -0.1932, -0.5117,  0.0812, -0.0436, -0.4701, -0.3534,  0.0366,  0.0466,\n",
       "                       -0.2054,  0.7910,  0.1765,  0.2685,  0.0756, -0.1731, -0.3128, -0.1135],\n",
       "                      [ 0.7212, -0.3751, -0.1755, -0.1486,  0.0753, -0.1785,  0.0226, -0.4290,\n",
       "                       -0.0560,  0.0702, -0.3267,  0.0720,  0.0207,  0.0190, -0.0170, -0.3154,\n",
       "                       -0.6238,  0.2393, -0.4800, -0.0287, -0.1894,  0.9316,  0.1199, -0.2673,\n",
       "                       -0.1497, -0.3910,  0.1311, -0.0581,  0.8429, -0.6121, -0.2875, -0.3504,\n",
       "                        0.3922,  0.6181, -0.2622, -0.3794,  0.0616,  0.0460, -0.4190, -0.1716]])),\n",
       "             ('classifier.3.bias',\n",
       "              tensor([ 0.2750, -0.4345,  0.2836,  0.0960, -0.1894, -0.3529,  0.6718,  0.1978,\n",
       "                      -0.2080, -0.4752]))])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.1) # Copilot is suggesting Adam instead of SGD\n",
    "accuracy_fn = accuracy_fn\n",
    "\n",
    "# What we want to optimize\n",
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f0420939a145c8aeb79a62170f9178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.1875, Train accuracy: 92.9750\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.1800, Train accuracy: 93.2967\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.1733, Train accuracy: 93.5233\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.1687, Train accuracy: 93.6867\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.1610, Train accuracy: 94.0100\n",
      "Test loss: 0.2790, Test accuracy: 90.8446\n",
      "Training time: 98.88 seconds on device:cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cb249bf6154325ae9f19dd673c630a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'loss': 0.16142641007900238,\n",
       " 'accuracy': 94.00833333333334}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start timer\n",
    "model_2_train_time_start = timer()\n",
    "\n",
    "# Number of epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_step(model_2, train_dataloader, loss_fn, optimizer, accuracy_fn, device)\n",
    "\n",
    "# Testing the model\n",
    "test_step(model_2, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "\n",
    "# End timer\n",
    "model_2_train_time_end = timer()\n",
    "# Print training time\n",
    "print_train_time(model_2_train_time_start, model_2_train_time_end, device)\n",
    "\n",
    "model_2_results = eval_model(model_2, train_dataloader, loss_fn, accuracy_fn)\n",
    "model_2_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
